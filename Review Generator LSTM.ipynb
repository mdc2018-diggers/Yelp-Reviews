{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerador de Reviews\n",
    "\n",
    "- Treinar um modelo preditivo no texto de todos os reviews\n",
    "- Gerar alguns review aleatórios\n",
    "\n",
    "### References\n",
    "- [\n",
    "Text Generation With LSTM Recurrent Neural Networks in Python with Keras](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/)\n",
    "- [Keras example - lstm_text_generation.py](https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py)\n",
    "- [textgenrnn - Easily train your own text-generating neural network of any size and complexity on any text dataset with a few lines of code.](https://github.com/minimaxir/textgenrnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q keras unidecode\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "#!pip install unidecode\n",
    "from unidecode import unidecode\n",
    "\n",
    "from util import dataset, gpu\n",
    "gpu.keras_share_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_text(text, vocabulary=None):\n",
    "    text = unidecode(text) # Replace unicode chars with closes ascii representation\n",
    "    text = text.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "    \n",
    "    if vocabulary is not None:\n",
    "        text = ''.join([\n",
    "            char\n",
    "            for char in text\n",
    "            if char in vocabulary\n",
    "        ])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'∅, ␃, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z, A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, \\n, \\t,  , ., ,, :, ;, ?, !, \\', \", `, /, |, \\\\, (, ), [, ], {, }, <, >, ~, @, #, $, ^, %, &, *, -, +, _, ='"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SYMBOL_PAD = '∅'\n",
    "SYMBOL_END = '␃'\n",
    "\n",
    "vocabulary = ''\n",
    "vocabulary += SYMBOL_PAD\n",
    "vocabulary += SYMBOL_END\n",
    "vocabulary += 'abcdefghijklmnopqrstuvwxyz'\n",
    "vocabulary += 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "vocabulary += '0123456789'\n",
    "vocabulary += '\\n\\t '\n",
    "vocabulary += '.,:;?!\\'\"`/|\\()[]{}<>~@#$^%&*-+_='\n",
    "\n",
    "char_to_int = {c: i for i, c in enumerate(vocabulary)}\n",
    "int_to_char = {i: c for i, c in enumerate(vocabulary)}\n",
    "vocabulary = set(vocabulary)\n",
    "\n",
    "', ' . join(int_to_char.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-10472bdcc0bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_normalize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mvocabulary_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mnum_chars\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vocabulary_prob = defaultdict(int)\n",
    "num_chars = 0\n",
    "for review in dataset.read('review'):\n",
    "    for char in _normalize_text(review['text']):\n",
    "        vocabulary_prob[char] += 1\n",
    "        num_chars += 1\n",
    "vocabulary_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0.3167662231700803,\n",
       " ' ': 18.496309239687296,\n",
       " '!': 0.24270328621570036,\n",
       " '\"': 0.0658344230868113,\n",
       " '#': 0.001655465559732789,\n",
       " '$': 0.036132408444559276,\n",
       " '%': 0.0038870196683405624,\n",
       " '&': 0.01704574057653688,\n",
       " \"'\": 0.3228658605082416,\n",
       " '(': 0.06755258929941653,\n",
       " ')': 0.07391775759034641,\n",
       " '*': 0.006360539383670845,\n",
       " '+': 0.003991380486544358,\n",
       " ',': 0.6182759888241178,\n",
       " '-': 0.11513228539558004,\n",
       " '.': 1.3212534059131404,\n",
       " '/': 0.026925511906330073,\n",
       " '0': 0.07466385327855339,\n",
       " '1': 0.061293044255942904,\n",
       " '2': 0.0508502294795502,\n",
       " '3': 0.03466714889219792,\n",
       " '4': 0.026039707380850277,\n",
       " '5': 0.0453628703288345,\n",
       " '6': 0.013668321516441465,\n",
       " '7': 0.011145987870015858,\n",
       " '8': 0.011397632101007268,\n",
       " '9': 0.013623294873103537,\n",
       " ':': 0.031549790258110354,\n",
       " ';': 0.009580154787208103,\n",
       " '<': 5.8913365115045875e-06,\n",
       " '=': 0.0013731022169313906,\n",
       " '>': 5.8913365115045875e-06,\n",
       " '?': 0.036788871655841215,\n",
       " '@': 0.0007204262934068467,\n",
       " 'A': 0.15048745823037155,\n",
       " 'B': 0.0903293378723949,\n",
       " 'C': 0.09361628283606364,\n",
       " 'D': 0.06862439173475954,\n",
       " 'E': 0.09032050086762765,\n",
       " 'F': 0.06451518451798509,\n",
       " 'G': 0.06348209657971768,\n",
       " 'H': 0.08341880014440002,\n",
       " 'I': 0.6574028794555247,\n",
       " 'J': 0.026012775556797683,\n",
       " 'K': 0.021913667774042956,\n",
       " 'L': 0.06557857075831167,\n",
       " 'M': 0.10502317275158898,\n",
       " 'N': 0.07778542001014917,\n",
       " 'O': 0.09243380743625451,\n",
       " 'P': 0.0645076099424703,\n",
       " 'Q': 0.006181695239571599,\n",
       " 'R': 0.05922223947214904,\n",
       " 'S': 0.1578251178554505,\n",
       " 'T': 0.36148946267766574,\n",
       " 'U': 0.02493844826294974,\n",
       " 'V': 0.044777523965441435,\n",
       " 'W': 0.1415641874641962,\n",
       " 'X': 0.0026367938986491244,\n",
       " 'Y': 0.040595095852024005,\n",
       " 'Z': 0.005445698985384348,\n",
       " '[': 0.00029540844507687286,\n",
       " '\\\\': 6.143822361997641e-05,\n",
       " ']': 0.00032276107888028704,\n",
       " '^': 0.00013423831051214024,\n",
       " '_': 0.0009792242901622268,\n",
       " '`': 0.00011446025222351769,\n",
       " 'a': 6.4123797784940795,\n",
       " 'b': 1.157504549195372,\n",
       " 'c': 2.1036544553722614,\n",
       " 'd': 3.204140124950787,\n",
       " 'e': 9.885093310711836,\n",
       " 'f': 1.626972531504648,\n",
       " 'g': 1.5490625518082555,\n",
       " 'h': 3.8210779387672913,\n",
       " 'i': 4.778690702556565,\n",
       " 'j': 0.1024587581300812,\n",
       " 'k': 0.7650186610819265,\n",
       " 'l': 3.1140296081488192,\n",
       " 'm': 1.7579739734134672,\n",
       " 'n': 4.8089700681769445,\n",
       " 'o': 5.760965442602499,\n",
       " 'p': 1.4402516704895199,\n",
       " 'q': 0.06957542177161671,\n",
       " 'r': 4.48856594471101,\n",
       " 's': 4.6367721932821775,\n",
       " 't': 6.79114432306248,\n",
       " 'u': 2.160473871167218,\n",
       " 'v': 0.9363071661051683,\n",
       " 'w': 1.7664722263313126,\n",
       " 'x': 0.16598461892388436,\n",
       " 'y': 1.762972351633728,\n",
       " 'z': 0.11117751535735718,\n",
       " '{': 3.3243970314918746e-05,\n",
       " '|': 4.5868262839571426e-05,\n",
       " '}': 3.6610448321492794e-05,\n",
       " '~': 0.000813004438587633,\n",
       " '\\x7f': 4.2080975082175623e-07}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_prob_sorted = {\n",
    "    k: v*100/num_chars\n",
    "    for v, k in sorted([(v,k) for k, v in vocabulary_prob.items()], reverse=True)\n",
    "}\n",
    "vocabulary_prob_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has character missing from vocabulary: ('\\x7f', 4.2080975082175623e-07)\n"
     ]
    }
   ],
   "source": [
    "for char, prob in vocabulary_prob_sorted.items():\n",
    "    if char not in vocabulary:\n",
    "        print('Dataset has character missing from vocabulary:', (char, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def resize_context(context, size):\n",
    "    context = list(context)\n",
    "    if len(context) > size:\n",
    "        context = context[-size:]\n",
    "    elif len(context) < size:\n",
    "        context = [SYMBOL_PAD] * (size-len(context)) + context\n",
    "    \n",
    "    return context\n",
    "\n",
    "def gen_trainning_data(context_size=50, batch_size=50):\n",
    "    def random_text_slice(text):\n",
    "        text = _normalize_text(text, vocabulary=vocabulary)\n",
    "        offset = random.randint(0, len(text))\n",
    "        context = resize_context(text[:offset], size=context_size)\n",
    "        if offset < len(text):\n",
    "            next_char = text[offset]\n",
    "        else:\n",
    "            next_char = SYMBOL_END\n",
    "\n",
    "        return context, next_char\n",
    "                \n",
    "    data = dataset.read('review', \n",
    "            repeat=True, \n",
    "            map=lambda review: random_text_slice(review['text']),\n",
    "            batch_size=batch_size\n",
    "    )\n",
    "    #return data\n",
    "    for batch in data:\n",
    "        #print(batch)\n",
    "        context = [[char_to_int[z] for z in x[0]] for x in batch]\n",
    "        next_char = [char_to_int[x[1]] for x in batch]\n",
    "        \n",
    "        context = np_utils.to_categorical(context, len(vocabulary))\n",
    "        next_char = np_utils.to_categorical(next_char, len(vocabulary))\n",
    "        yield context, next_char\n",
    "\n",
    "#next(gen_trainning_data(context_size=3, batch_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def gen_texts(prefixes=['']*10, max_len=100, temperature=0.1):\n",
    "    context_size = model.input_shape[1]\n",
    "    result = []\n",
    "    while len(prefixes) != 0:\n",
    "        x = [resize_context(prefix, context_size) for prefix in prefixes]\n",
    "        x = np.array([\n",
    "            [char_to_int[char] for char in resize_context(prefix, context_size)]\n",
    "            for prefix in prefixes\n",
    "        ])\n",
    "        x = np_utils.to_categorical(x, len(vocabulary))\n",
    "        \n",
    "        predictions = model.predict(x, verbose=0)\n",
    "        predictions = [int_to_char[sample(p, temperature=temperature)] for p in predictions]\n",
    "        \n",
    "        result += [\n",
    "            prefix + ('…' if next_char != SYMBOL_END else '')\n",
    "            for prefix, next_char in zip(prefixes, predictions)\n",
    "            if next_char == SYMBOL_END or len(prefix) >= max_len\n",
    "        ]\n",
    "        prefixes = [\n",
    "            prefix + next_char\n",
    "            for prefix, next_char in zip(prefixes, predictions)\n",
    "            if next_char != SYMBOL_END and len(prefix) < max_len\n",
    "        ]\n",
    "    return result\n",
    "        \n",
    "def gen_text(prefix='', max_len=100, temperature=0.1):\n",
    "    return gen_texts(prefixes=[prefix], max_len=max_len, temperature=temperature)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 50, 512)           1253376   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 50, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 99)                50787     \n",
      "=================================================================\n",
      "Total params: 5,502,563\n",
      "Trainable params: 5,502,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(units=(512, 512, 512), dropout=(0.2, 0.2, 0.2), context_size=50):\n",
    "\n",
    "    model = Sequential()\n",
    "    for i, (lstm_units, lstm_dropout) in enumerate(zip(units, dropout)):\n",
    "        extra_args = {}\n",
    "        if i == 0:\n",
    "            extra_args['input_shape'] = (context_size, len(vocabulary))\n",
    "        extra_args['return_sequences'] = i < len(units) - 1\n",
    "\n",
    "\n",
    "        model.add(LSTM(lstm_units, **extra_args))\n",
    "        if lstm_dropout != 0:\n",
    "            model.add(Dropout(lstm_dropout))\n",
    "            \n",
    "    model.add(Dense(len(vocabulary), activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.load_weights('review-generator-weights-816-1.2344.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "100/100 [==============================] - 20s 202ms/step - loss: 1.3302\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.33023, saving model to review-generator-weights-01-1.3302.h5\n",
      "\n",
      " ---x---\n",
      "I was a great service and the service is always so…\n",
      " ---x---\n",
      "The service is always a great place to go back aga…\n",
      " ---x---\n",
      "The service is always a great service and the serv…\n",
      " ---x---\n",
      "The service is always a great place to go back aga…\n",
      " ---x---\n",
      "I was a great place to go to the staff and the ser…\n",
      " ---x---\n",
      "\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 1.2983\n",
      "\n",
      "Epoch 00002: loss improved from 1.33023 to 1.29833, saving model to review-generator-weights-02-1.2983.h5\n",
      "\n",
      " ---x---\n",
      "I was a great service and I will be back again.\n",
      " ---x---\n",
      "I was a great place to go back and the staff was g…\n",
      " ---x---\n",
      "The service was good and the service was good and …\n",
      " ---x---\n",
      "The service is always friendly and the food was go…\n",
      " ---x---\n",
      "I had a great service that I was a great place to …\n",
      " ---x---\n",
      "\n",
      "Epoch 3/1000\n",
      "  5/100 [>.............................] - ETA: 16s - loss: 1.2925"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-662c59f0c93f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     callbacks=[\n\u001b[1;32m     10\u001b[0m         \u001b[0mcheckpoint_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0meval_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     ])\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_callbacks = ModelCheckpoint('review-generator-weights-{epoch:02d}-{loss:.4f}.h5', monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "eval_callback = LambdaCallback(on_epoch_end=lambda epoch, logs: print('\\n ---x---\\n'.join([''] + gen_texts(['']*5, max_len=50) + [''])))\n",
    "\n",
    "# fit the model\n",
    "model.fit_generator(\n",
    "    gen_trainning_data(batch_size=100), \n",
    "    epochs=1000, \n",
    "    steps_per_epoch=100,\n",
    "    callbacks=[\n",
    "        checkpoint_callbacks,\n",
    "        eval_callback\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have been the food is the best service and I will be back.\n",
      "-------x--------\n",
      "We will be back to this place and the salad was always a great place for a fantastic service. I will be back again.\n",
      "-------x--------\n",
      "This place is a service and the staff was good.  The salad was good and the food was good.  The price was good for a very salad to the staff and the menu is a good place to go back.\n",
      "-------x--------\n",
      "I had the counter and the staff is always a good deal of the price and the staff was a show on the staff and it was delicious. The chicken was on the staff and we were the best place to go back for the staff and the staff was so good and the service was good and the food was good.\n",
      "-------x--------\n",
      "All the staff was okay and great and he was a little spot of beef and the company was a little considerable. We were so much looking for a staff and was good and the food was a bit of the best service in the pork that is a great selection of pork to the hotel in the food and the service is always super worth it.  I will be back again!\n",
      "-------x--------\n",
      "I was able to have the same beer place for a business that was a great place to go back and the food was good.  The price is a great food. The service is a good place to get a bit of the best to the staff and they have a salad with the staff and the service is always good and he was a great place for a good food and we were all the best and I will definitely be back for the best things that we had a bit of the considerable and I will be back again.\n",
      "-------x--------\n",
      "I will be back again and they have to get the price for a good selection of things on the price.  The food was good and the best place to get a company with the pork from the pork salad with a try that we were standing to the time to make you want to get a business to try the card and the show was good.  The only of the strip and we weren't better than the best portions are so happy with a server and beautiful service. I will be back and it was a good place to go back.\n",
      "-------x--------\n",
      "I will be back and the staff was fresh and the service is the best company and the staff was a good place to get a great place to go back and we were all the best salad and the wine was nice and excellent and the service was so good.  I had the restaurant in a super staff and the food was pretty good.  I had the location with the best portions and I had the try the way to get the best people with the salad to make the problem they were all of the bar and the food was good.  The price is a great …\n",
      "-------x--------\n",
      "I was sure I was a bit of the staff and did not have to get the same place. The restaurant is on the staff on the best service.  I will definitely be back and the staff was good and the restaurant was good.  The food was good and the service is always good and the friend was a good place to go back and the staff was the best morning that I was a good place to go back for a service restaurant.  I will be back again and they have a company to this place for the staff and the service is wonderful a…\n",
      "-------x--------\n",
      "I have been the best place to go back and the staff was a good place to eat. I have been the restaurant in the staff in the best service for a really friend and I was the best butter and have been in the best pork chicken in the straight. I will definitely be back for a lot of the staff and the staff was delicious. I will definitely be back for a great food and the price was a great food for a server and the service is a great place to get a few months and our chicken was good and the food was g…\n",
      "-------x--------\n"
     ]
    }
   ],
   "source": [
    "#Generate a few random review-like texts\n",
    "for x in gen_texts(temperature=0.3, max_len=500):\n",
    "    print(x)\n",
    "    print('-------x--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### I love this plac"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " - …e to go back and was a bit so …\n",
       " - …e for the staff and the chicke…\n",
       " - …e for a lot of the considerabl…\n",
       " - …e.  I will be back to this pla…\n",
       " - …e. The service was good and th…"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-093e2b4c9a2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretty_prefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mprefix_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mpretty_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'…'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpretty_prefix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretty_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprefix_len\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mcompletions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         display(\n",
      "\u001b[0;32m<ipython-input-8-b03c044c6025>\u001b[0m in \u001b[0;36mgen_texts\u001b[0;34m(prefixes, max_len, temperature)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1165\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Autocomplete animation\n",
    "\n",
    "prefix_len = 80\n",
    "for autocomplete_text in dataset.read('review', map=lambda review:_normalize_text(review['text'])):\n",
    "    prefix = \"\"\n",
    "    for char in [\"\"] + list(autocomplete_text):\n",
    "        prefix += char\n",
    "        pretty_prefix = '[empty]' if prefix == '' else prefix\n",
    "        if len(pretty_prefix) > prefix_len: \n",
    "            pretty_prefix = '…' + pretty_prefix[len(pretty_prefix)-prefix_len+1:]\n",
    "        completions = gen_texts(prefixes=[prefix]*5, max_len=len(prefix)+30, temperature=0.3)\n",
    "        clear_output()\n",
    "        display(\n",
    "            Markdown('### ' + pretty_prefix),\n",
    "            Markdown('\\n'.join(' - ' + ('…' if prefix else '') + x[len(prefix):] for x in (completions))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\\\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Considerações de Performance\n",
    "\n",
    "Essa implementação foi feita com simplicidade e legibilidade em mente, e é terrivelmente ineficiente.\n",
    "\n",
    "### Treino\n",
    "Para começar, a cada review, um único trecho de 50 caracteres é extraido e usado para treinar um único caracter de saida.\n",
    "\n",
    "Em outras palavras, este código processa uma função _extremamente_ complexa, com 5 milhões de parametros, para simplesmente descartar os resultados intermediários e considerar apenas um entre centenas de caracteres no cálculo de loss.\n",
    "\n",
    "Uma solução melhor deveria levar em consideração a estrutura do LSTM: É possível prever o próximo caracter para cada um dos elementos da sequencia e usar predições intermediárias no cálculo de loss, efetivamente treinando todas as letras da sequencia simultaneamente.\n",
    "\n",
    "### Predição\n",
    "A predição também é feita de forma idiota. Para cada caractere a ser predito, o trecho completo dos 50 caracteres anteriores é alimentado na rede neural, causando uma quantidade enorme de calculos redundantes.\n",
    "\n",
    "Uma versão mais eficiente deveria preservar o estado da LSTM e calcular apenas a predição do próximo caractere.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usos\n",
    "\n",
    "Gerar texto que se parece com uma review é divertido, mas não é terrívelmente útil.\n",
    "\n",
    "Um uso mais interessante é no auxilio a digitação, especialmente em celulares. Isto me lembrou do [Dasher](http://www.inference.org.uk/dasher/) ([Demo](https://www.youtube.com/watch?v=nr3s4613DX8)), um projeto que existe há muitos anos e que certamente não usa redes neurais, mas que talvez poderia ser um bom teclado android."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
